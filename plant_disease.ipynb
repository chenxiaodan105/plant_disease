{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "'''\n",
    "https://arxiv.org/abs/1608.06993\n",
    "https://github.com/liuzhuang13/DenseNet\n",
    "https://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n",
    "https://pytorch.org/docs/stable/torchvision/models.html\n",
    "https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31718\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disease_class</th>\n",
       "      <th>image_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>62fd8bf4d53a1b94fbac16738406f10b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0bdec5cccbcade6b6e94087cb5509d98.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8951e940341f77c8d361c1872c67b16d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7ed158da58c451f75fb790530d6f19cc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>9b7399aa-1c3c-4137-ae4e-196cd23fe573___FREC_Sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   disease_class                                           image_id\n",
       "0              1               62fd8bf4d53a1b94fbac16738406f10b.jpg\n",
       "1              1               0bdec5cccbcade6b6e94087cb5509d98.jpg\n",
       "2              1               8951e940341f77c8d361c1872c67b16d.jpg\n",
       "3              1               7ed158da58c451f75fb790530d6f19cc.jpg\n",
       "4              1  9b7399aa-1c3c-4137-ae4e-196cd23fe573___FREC_Sc..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle \n",
    "seed = 34\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "use_gpu = True\n",
    "\n",
    "# data agumentation and normalization for training\n",
    "trans_train = transforms.Compose([transforms.RandomResizedCrop(size=224),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomRotation(30),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trans_valid = transforms.Compose([transforms.Resize(size=224),\n",
    "                                  transforms.CenterCrop(size=224),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "# inputs\n",
    "batch_size = 128\n",
    "num_epochs = 20\n",
    "stops = 5\n",
    "\n",
    "# load data\n",
    "train_path = 'C:/Users/HP/Desktop/ai_challenger_pdr2018_trainingset_20181023/AgriculturalDisease_trainingset/images'\n",
    "val_path = 'C:/Users/HP/Desktop/Test_images'\n",
    "\n",
    "train=pd.read_json('C:/Users/HP/Desktop/ai_challenger_pdr2018_trainingset_20181023/AgriculturalDisease_trainingset/AgriculturalDisease_train_annotations.json')\n",
    "print(len(train))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disease_class:61\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60}\n",
      "[1185, 211, 152, 427, 142, 40, 598, 116, 110, 376, 191, 167, 483, 355, 208, 498, 815, 294, 381, 462, 503, 419, 61, 630, 367, 1828, 1799, 251, 857, 770, 1025, 287, 377, 1430, 203, 510, 251, 446, 242, 192, 583, 1208, 319, 966, 1, 1, 251, 442, 264, 1109, 325, 336, 43, 22, 421, 807, 542, 271, 1414, 2473, 261]\n",
      "[169, 30, 22, 61, 20, 6, 85, 12, 18, 54, 27, 24, 69, 51, 29, 71, 116, 42, 54, 66, 74, 59, 9, 90, 52, 269, 262, 36, 122, 110, 147, 40, 54, 204, 29, 73, 36, 64, 35, 27, 83, 173, 46, 138, 1, 0, 36, 63, 38, 158, 46, 48, 4, 5, 60, 115, 77, 39, 202, 353, 37]\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train)\n",
    "categories = set(train['disease_class'])\n",
    "n_class = len(categories)\n",
    "print('disease_class:{}\\n{}'.format(n_class,categories))\n",
    "\n",
    "number_of_classes = []\n",
    "for i in range(n_class):\n",
    "    number_of_classes.append(list(train['disease_class']).count(i))\n",
    "print(number_of_classes)\n",
    "\n",
    "val = pd.read_json('C:/Users/HP/Desktop/validation_labels.json')\n",
    "n_val = len(val)\n",
    "number_of_classes = []\n",
    "for i in range(n_class):\n",
    "    number_of_classes.append(list(val['disease_class']).count(i))\n",
    "print(number_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\torchvision\\models\\densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n"
     ]
    }
   ],
   "source": [
    "num_class = n_class\n",
    "model = models.densenet201()\n",
    "\n",
    "# set the .requires_grad attribute of the parameters \n",
    "print(\"Params to learn:\")\n",
    "for para in list(model.parameters()):\n",
    "    para.requires_grad=False\n",
    "for para in list(model.features.denseblock3.parameters()):\n",
    "    para.requires_grad=True\n",
    "for para in list(model.features.transition3.parameters()):\n",
    "    para.requires_grad=True\n",
    "for para in list(model.features.denseblock4.parameters()):\n",
    "    para.requires_grad=True\n",
    "for para in list(model.features.norm5.parameters()):\n",
    "    para.requires_grad=True\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1920, num_class),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the model to a GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model and dataparallel\n",
    "cuda_device_ids = [0,1]\n",
    "model = model.cuda(cuda_device_ids[0])\n",
    "model = nn.DataParallel(model, device_ids=cuda_device_ids)\n",
    "model.load_state_dict(torch.load('C:/Users/HP/Desktop/densenet201.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DenseNet model\n",
    "class Model(Dataset):\n",
    "    def __init__(self, df_data, data_dir = './', transform=None):\n",
    "        super().__init__()\n",
    "        self.df = df_data.values\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label,img_name = self.df[index]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        with Image.open(img_path) as img:\n",
    "            image = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "dataset_train = Model(df_data=train, \n",
    "    data_dir=train_path, transform=trans_train)\n",
    "dataset_valid = Model(df_data=val, \n",
    "    data_dir=val_path, transform=trans_valid)\n",
    "\n",
    "loader_train = DataLoader(dataset = dataset_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "loader_valid = DataLoader(dataset = dataset_valid, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize the parameters\n",
    "params_to_update = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cross-entropy loss function that accepts soft target\n",
    "def cross_entropy(input, target, size_average=True):\n",
    "    logsoftmax = nn.LogSoftmax()\n",
    "    if size_average:\n",
    "        return torch.mean(torch.sum(-target * logsoftmax(input), dim=1))\n",
    "    else:\n",
    "        return torch.sum(torch.sum(-target * logsoftmax(input), dim=1))\n",
    "    \n",
    "criterion = cross_entropy\n",
    "optimizer = optim.SGD(params_to_update,lr = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "best_val_acc = 0.875\n",
    "best_epoch = 0\n",
    "epoch_since = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    # schedule the learning rate\n",
    "    scheduler.step()\n",
    "    model.train() # Set model to training mode\n",
    "    \n",
    "    train_total_samples = 0\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    # iterate over data.\n",
    "    for i, data in enumerate(loader_train):\n",
    "        print('.',end='')        \n",
    "        # get the inputs\n",
    "        inputs, label = data\n",
    "        train_total_samples += label.size()[0]        \n",
    "        labels = label.resize(label.size()[0], 1)\n",
    "        # convert labels to a one-hot variable\n",
    "        labels = torch.FloatTensor(label.size()[0], n_class).zero_().scatter_(1, labels.resize(label.size()[0], 1) ,1)\n",
    "        labels = (1 - label_smoothing) * labels + (label_smoothing / n_class)\n",
    "        if use_gpu:\n",
    "            inputs, labels, label = inputs.cuda(), labels.cuda(), label.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # statistics\n",
    "        train_pred = torch.argmax(outputs.data, dim=1)        \n",
    "        train_acc += torch.sum(train_pred == label.data)\n",
    "        train_loss += loss.item() * labels.size()[0]\n",
    "            \n",
    "    model.eval()\n",
    "    valid_total_samples = 0\n",
    "    valid_acc = 0\n",
    "    val_loss = 0 \n",
    "    \n",
    "    for _, data in enumerate(loader_valid):     \n",
    "        inputs, label = data\n",
    "        valid_total_samples += label.size()[0]        \n",
    "        labels = label\n",
    "        labels = torch.FloatTensor(label.size()[0], n_class).zero_().scatter_(1, labels.resize(label.size()[0], 1) ,1)\n",
    "        labels = (1 - label_smoothing) * labels + (label_smoothing / n_class)\n",
    "        if use_gpu:\n",
    "            inputs, labels, label = inputs.cuda(), labels.cuda(), label.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        valid_pred = torch.argmax(outputs.data, dim=1)        \n",
    "        valid_acc += torch.sum(valid_pred == label.data)\n",
    "        val_loss += loss.item() * labels.size()[0]\n",
    "    \n",
    "    # accuaracy and loss\n",
    "    train_acc = train_acc.cpu().numpy() / train_total_samples\n",
    "    valid_acc = valid_acc.cpu().numpy() / valid_total_samples\n",
    "    train_loss = train_loss / train_total_samples\n",
    "    val_loss = val_loss / valid_total_samples\n",
    "    print()\n",
    "    \n",
    "    time_elapsed = time.time()\n",
    "    print('[Epoch %d] train loss %.6f train acc %.6f  valid loss %.6f valid acc %.6f  time %.6f' % (\n",
    "        epoch, train_loss, train_acc, val_loss, valid_acc,time_elapsed-since))\n",
    "    \n",
    "    # save the best model\n",
    "    if valid_acc > best_val_acc:\n",
    "        best_val_acc = valid_acc\n",
    "        best_epoch = epoch\n",
    "        epoch_since = 0\n",
    "        print('save model...')\n",
    "        torch.save(model.state_dict(), 'tuned-densenet201.pth')\n",
    "        print('saved.')\n",
    "    else:\n",
    "        epoch_since += 1\n",
    "        \n",
    "    if epoch_since > stops:\n",
    "        break\n",
    "            \n",
    "print('Finished Training')\n",
    "print('best_epoch: %d, best_val_acc %.6f' % (best_epoch, best_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
